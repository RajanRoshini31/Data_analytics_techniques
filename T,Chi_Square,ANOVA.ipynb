{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOQbqUB6o7cjGuKc7gRFhxM"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["import numpy as np\n","import csv\n","\n","def one_sample_ttest(data, popmean, alpha):\n","    \"\"\"Performs a one-sample t-test.\"\"\"\n","    t_statistic = (np.mean(data) - popmean) / (np.std(data, ddof=1) / np.sqrt(len(data)))\n","    df = len(data) - 1  # Degrees of freedom\n","    critical_value = critical_values[alpha][df] if df <= 10 and alpha in critical_values else \"dof/alpha not in dictionary\"\n","    return t_statistic, critical_value\n","\n","def unpaired_ttest(data1, data2, alpha):\n","    \"\"\"Performs an unpaired t-test.\"\"\"\n","    n1, n2 = len(data1), len(data2)\n","    x1_bar, x2_bar = np.mean(data1), np.mean(data2)\n","    s1_sq, s2_sq = np.var(data1, ddof=1), np.var(data2, ddof=1)\n","\n","    sp = np.sqrt(((n1 - 1) * s1_sq + (n2 - 1) * s2_sq) / (n1 + n2 - 2))\n","    t_statistic = (x1_bar - x2_bar) / (sp * np.sqrt(1/n1 + 1/n2))\n","\n","    df = n1 + n2 - 2\n","    critical_value = critical_values[alpha][df] if df <= 10 and alpha in critical_values else \"dof/alpha not in dictionary\"\n","    return t_statistic, critical_value\n","\n","def paired_ttest(data1, data2, alpha):\n","    \"\"\"Performs a paired t-test.\"\"\"\n","    diff = np.array(data1) - np.array(data2)\n","    t_statistic = np.mean(diff) / (np.std(diff, ddof=1) / np.sqrt(len(diff)))\n","    df = len(diff) - 1  # Degrees of freedom\n","    critical_value = critical_values[alpha][df] if df <= 10 and alpha in critical_values else \"dof/alpha not in dictionary\"\n","    return t_statistic, critical_value\n","\n","# Manually defined dictionary of critical values\n","critical_values = {\n","    0.05: {\n","        1: 12.706, 2: 4.303, 3: 3.182, 4: 2.776, 5: 2.571,\n","        6: 2.447, 7: 2.365, 8: 2.306, 9: 2.262, 10: 2.228\n","    },\n","    0.025: {\n","        1: 63.657, 2: 9.925, 3: 5.841, 4: 4.604, 5: 4.032,\n","        6: 3.707, 7: 3.499, 8: 3.355, 9: 3.250, 10: 3.169\n","    },\n","    0.01: {\n","        1: 318.313, 2: 22.327, 3: 10.215, 4: 7.173, 5: 5.893,\n","        6: 5.208, 7: 4.782, 8: 4.499, 9: 4.296, 10: 4.143\n","    }\n","}\n","\n","# User input\n","test_type = input(\"Enter the type of t-test (one-sample, unpaired, paired): \")\n","file_path1 = input(\"Enter the file path for dataset 1 (CSV): \")\n","alpha = float(input(\"Enter the significance level (alpha): \"))\n","\n","# Read data from CSV file 1\n","with open(file_path1, 'r') as file1:\n","    reader1 = csv.reader(file1)\n","    data1 = [float(row[0]) for row in reader1]  # Assuming data is in the first column\n","\n","if test_type in (\"unpaired\", \"paired\"):\n","    file_path2 = input(\"Enter the file path for dataset 2 (CSV): \")\n","    with open(file_path2, 'r') as file2:\n","        reader2 = csv.reader(file2)\n","        data2 = [float(row[0]) for row in reader2]  # Assuming data is in the first column\n","\n","# Get population mean if needed\n","if test_type == \"one-sample\":\n","    popmean = float(input(\"Enter the population mean: \"))\n","\n","# Perform the selected t-test\n","if test_type == \"one-sample\":\n","    t_statistic, critical_value = one_sample_ttest(data1, popmean, alpha)\n","elif test_type == \"unpaired\":\n","    t_statistic, critical_value = unpaired_ttest(data1, data2, alpha)\n","elif test_type == \"paired\":\n","    t_statistic, critical_value = paired_ttest(data1, data2, alpha)\n","else:\n","    print(\"Invalid test type.\")\n","    exit()\n","\n","# Print results\n","print(\"T-statistic:\", t_statistic)\n","print(\"Critical value:\", critical_value)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":373},"id":"v658Ko7RbTBC","executionInfo":{"status":"error","timestamp":1737187342028,"user_tz":-330,"elapsed":78164,"user":{"displayName":"Roshini Rajan","userId":"05105296642670067175"}},"outputId":"ffb94aa3-fb67-4a61-ef8e-fb92d03c8a27"},"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["Enter the type of t-test (one-sample, unpaired, paired): one-sample\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"Interrupted by user","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-3dcb879f9d8c>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;31m# User input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0mtest_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Enter the type of t-test (one-sample, unpaired, paired): \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m \u001b[0mfile_path1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Enter the file path for dataset 1 (CSV): \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m \u001b[0malpha\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Enter the significance level (alpha): \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    849\u001b[0m                 \u001b[0;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m             )\n\u001b[0;32m--> 851\u001b[0;31m         return self._input_request(str(prompt),\n\u001b[0m\u001b[1;32m    852\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    853\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"]}]},{"cell_type":"code","source":["\n","def one_sample_ttest(data, popmean, alpha):\n","    \"\"\"Performs a one-sample t-test.\"\"\"\n","    t_statistic = (np.mean(data) - popmean) / (np.std(data, ddof=1) / np.sqrt(len(data)))\n","    df = len(data) - 1  # Degrees of freedom\n","    critical_value = critical_values[alpha][df] if df <= 10 and alpha in critical_values else \"dof/alpha not in dictionary\"\n","    return t_statistic, critical_value\n","\n","critical_values = {\n","    0.05: {\n","        1: 12.71, 2: 4.303, 3: 3.182, 4: 2.776, 5: 2.571,\n","        6: 2.447, 7: 2.365, 8: 2.306, 9: 2.262, 10: 2.228\n","    },\n","    0.20: {\n","        1: 3.078, 2: 1.886, 3: 1.638, 4:1.533, 5: 1.476,\n","        6: 1.440, 7: 1.415, 8:1.397, 9: 1.383, 10: 1.372\n","    },\n","    0.5: {\n","        1: 1.00, 2:0.816, 3: 0.765, 4: 0.741, 5: 0.727,\n","        6: 0.718, 7:0.711 ,8:0.706, 9: 0.703, 10: 0.700\n","    }\n","}\n","test_type = input(\"Enter the type of t-test (one-sample, unpaired, paired): \")\n","alpha = float(input(\"Enter the significance level (alpha): \"))\n","\n","\n","if test_type in (\"unpaired\", \"paired\"):\n","    file_path1 = input(\"Enter the file path for dataset 1 (CSV): \")\n","    with open(file_path1, 'r') as file1:\n","      reader1 = csv.reader(file1)\n","      data1 = [float(row[0]) for row in reader1]\n","    file_path2 = input(\"Enter the file path for dataset 2 (CSV): \")\n","    with open(file_path2, 'r') as file2:\n","        reader2 = csv.reader(file2)\n","        data2 = [float(row[0]) for row in reader2]\n","\n","if test_type == \"one-sample\":\n","    popmean = float(input(\"Enter the population mean: \"))\n","    t_statistic, critical_value = one_sample_ttest(data1, popmean, alpha)\n","data1 = [float(row[0]) for row in reader1]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":228},"id":"i_-mSmBEb3Kq","executionInfo":{"status":"error","timestamp":1737188658756,"user_tz":-330,"elapsed":25116,"user":{"displayName":"Roshini Rajan","userId":"05105296642670067175"}},"outputId":"5957d3af-eccc-4ec0-ad5e-7533e4dd56c6"},"execution_count":null,"outputs":[{"name":"stdout","output_type":"stream","text":["Enter the type of t-test (one-sample, unpaired, paired): one-sample\n","Enter the significance level (alpha): 0.05\n","Enter the population mean: 75\n"]},{"output_type":"error","ename":"NameError","evalue":"name 'data1' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-2-f3840724d34c>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtest_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"one-sample\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0mpopmean\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Enter the population mean: \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m     \u001b[0mt_statistic\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcritical_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mone_sample_ttest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpopmean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'data1' is not defined"]}]},{"cell_type":"code","source":["import math\n","\n","def get_t_distribution():\n","    return {\n","        # Degrees of Freedom: {Significance Levels (Two-Tailed)}\n","        1: {0.05: 12.71, 0.20: 3.078, 0.50: 1.000},\n","        2: {0.05: 4.303, 0.20: 1.886, 0.50: 0.816},\n","        3: {0.05: 3.182, 0.20: 1.638, 0.50: 0.765},\n","        4: {0.05: 2.776, 0.20: 1.533, 0.50: 0.741 },\n","        5: {0.05: 2.571, 0.20: 1.476, 0.50: 0.727},\n","        6: {0.05: 2.447, 0.20: 1.440, 0.50: 0.718},\n","        7: {0.05: 2.365, 0.20: 1.415, 0.50: 0.711},\n","        8: {0.05: 2.306, 0.20: 1.397, 0.50: 0.706},\n","        9: {0.05: 2.262, 0.20: 1.383, 0.50:  0.703},\n","        10: {0.05: 2.228, 0.20: 1.372, 0.50: 0.700},\n","        11: {0.05: 2.201, 0.20: 1.363, 0.50: 0.697},\n","        12: {0.05: 2.179, 0.20: 1.356, 0.50: 0.695},\n","        13: {0.05: 2.160, 0.20: 1.350, 0.50: 0.694},\n","        14: {0.05: 2.145, 0.20: 1.345, 0.50: 0.692},\n","        15: {0.05: 2.131, 0.20: 1.341, 0.50: 0.691},\n","    }\n","\n","def one_sample_test():\n","    population_mean = float(input(\"Enter the population mean: \"))\n","    sample_mean = float(input(\"Enter the sample mean: \"))\n","    std_dev = float(input(\"Enter the standard deviation: \"))\n","    sample_size = int(input(\"Enter the sample size: \"))\n","    alpha = float(input(\"Enter the significance level (e.g., 0.05, 0.20, 0.50): \"))\n","\n","    t_calculated = abs((sample_mean - population_mean) / (std_dev / math.sqrt(sample_size)))\n","    degrees_of_freedom = sample_size - 1\n","\n","    t_distribution = get_t_distribution()\n","\n","    if degrees_of_freedom in t_distribution and alpha in t_distribution[degrees_of_freedom]:\n","        t_critical = t_distribution[degrees_of_freedom][alpha]\n","        print(f\"Calculated t-value: {t_calculated:.3f}\")\n","        print(f\"Critical t-value: {t_critical}\")\n","        if t_calculated > t_critical:\n","            print(\"Result: Reject the null hypothesis.\")\n","        else:\n","            print(\"Result: Accept the null hypothesis.\")\n","    else:\n","        print(\"Critical t-value not available for the given degrees of freedom and alpha.\")\n","\n","one_sample_test()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FtgBvwTThtMm","executionInfo":{"status":"ok","timestamp":1737188926143,"user_tz":-330,"elapsed":32434,"user":{"displayName":"Roshini Rajan","userId":"05105296642670067175"}},"outputId":"f96e5a30-ee82-4982-ae54-e5f91e72de60"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Enter the population mean: 75\n","Enter the sample mean: 72\n","Enter the standard deviation: 5\n","Enter the sample size: 10\n","Enter the significance level (e.g., 0.05, 0.20, 0.50): 0.05\n","Calculated t-value: 1.897\n","Critical t-value: 2.262\n","Result: Fail to reject the null hypothesis.\n"]}]},{"cell_type":"code","source":["def unpaired_test():\n","  file_path1 = input(\"Enter the file path for dataset 1 (CSV): \")\n","  with open(file_path1, 'r') as file1:\n","      reader1 = csv.reader(file1)\n","      data1 = [float(row[0]) for row in reader1]\n","  mean1 = sum(data1) / len(data1)\n","  variance1 = sum([(x - mean1)**2 for x in data1]) / (len(data1) - 1)  # Sample variance\n","\n","\n","  file_path2 = input(\"Enter the file path for dataset 2 (CSV): \")\n","  with open(file_path2, 'r') as file2:\n","      reader2 = csv.reader(file2)\n","      data2 = [float(row[0]) for row in reader2]\n","  mean2 = sum(data2) / len(data2)\n","  variance2 = sum([(x - mean2)**2 for x in data2]) / (len(data2) - 1)  # Sample variance\n","  alpha = float(input(\"Enter the significance level (e.g., 0.05, 0.20, 0.50): \"))\n","  n1,n2=len(data1),len(data2)\n","  t_statistic = (mean1 - mean2) / math.sqrt((variance1 / n1) + (variance2 / n2))\n","  t_distribution = get_t_distribution()\n","  degrees_of_freedom = n1+n2-2\n","\n","  if degrees_of_freedom in t_distribution and alpha in t_distribution[degrees_of_freedom]:\n","        t_critical = t_distribution[degrees_of_freedom][alpha]\n","        print(f\"Calculated t-value: {t_statistic:.3f}\")\n","        print(f\"Critical t-value: {t_critical}\")\n","        if t_statistic > t_critical:\n","            print(\"Result: Reject the null hypothesis.\")\n","        else:\n","            print(\"Result: Accept the null hypothesis.\")\n","  else:\n","        print(\"Critical t-value not available for the given degrees of freedom and alpha.\")\n","unpaired_test()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aVIh-3PKiKEI","executionInfo":{"status":"ok","timestamp":1737190440162,"user_tz":-330,"elapsed":77709,"user":{"displayName":"Roshini Rajan","userId":"05105296642670067175"}},"outputId":"87d069f5-fb2f-4664-ce5c-c29426926a43"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Enter the file path for dataset 1 (CSV): /content/drive/MyDrive/DA/A - Sheet1.csv\n","Enter the file path for dataset 2 (CSV): /content/drive/MyDrive/DA/B - Sheet1.csv\n","Enter the significance level (e.g., 0.05, 0.20, 0.50): 0.05\n","Calculated t-value: 4.801\n","Critical t-value: 2.306\n","Result: Reject the null hypothesis.\n"]}]},{"cell_type":"code","source":["import math\n","import csv\n","\n","def paired_test():\n","    file_path = input(\"Enter the file path for the dataset (CSV): \")\n","    with open(file_path, 'r') as file:\n","        reader = csv.reader(file)\n","        next(reader)  # Skip the header row if present\n","        data = []\n","        for row in reader:\n","            try:\n","                x1 = float(row[0])\n","                x2 = float(row[1])\n","                data.append((x1, x2))  # Store as tuples (x1, x2)\n","            except (IndexError, ValueError):\n","                print(f\"Skipping invalid row: {row}\")\n","\n","    alpha = float(input(\"Enter the significance level (e.g., 0.05, 0.20, 0.50): \"))\n","\n","    # Calculate differences\n","    differences = [x1 - x2 for x1, x2 in data]\n","     # Calculate mean and variance of differences\n","    mean_diff = sum(differences) / len(differences)\n","    variance_diff = sum([(x - mean_diff)**2 for x in differences]) / (len(differences) - 1)\n","\n","    # Calculate t-statistic\n","    t_statistic = mean_diff / (math.sqrt(variance_diff / len(differences)))\n","\n","    # Degrees of freedom\n","    degrees_of_freedom = len(differences) - 1\n","\n","    t_distribution = get_t_distribution()\n","\n","    # Check if degrees of freedom and alpha are in the t_distribution dictionary\n","    if degrees_of_freedom in t_distribution and alpha in t_distribution[degrees_of_freedom]:\n","        t_critical = t_distribution[degrees_of_freedom][alpha]\n","        print(f\"Calculated t-value: {t_statistic:.3f}\")\n","        print(f\"Critical t-value: {t_critical:.3f}\")\n","\n","        # Check if calculated t-statistic exceeds the critical value\n","        if abs(t_statistic) > t_critical:  # Use abs() for two-tailed test\n","            print(\"Result: Reject the null hypothesis.\")\n","        else:\n","            print(\"Result: Fail to reject the null hypothesis.\")\n","    else:\n","        print(\"Critical t-value not available for the given degrees of freedom and alpha.\")\n","paired_test()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"edCBqtf9pJgU","executionInfo":{"status":"ok","timestamp":1737191380305,"user_tz":-330,"elapsed":33572,"user":{"displayName":"Roshini Rajan","userId":"05105296642670067175"}},"outputId":"22fcea2a-8677-43c8-c5d7-c185b6755472"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Enter the file path for the dataset (CSV): /content/drive/MyDrive/DA/k1 - Sheet1.csv\n","Enter the significance level (e.g., 0.05, 0.20, 0.50): 0.50\n","Calculated t-value: -4.264\n","Critical t-value: 0.694\n","Result: Reject the null hypothesis.\n"]}]},{"cell_type":"markdown","source":["**CHI-SQAURE-TEST**"],"metadata":{"id":"Ib_MGgX99Cry"}},{"cell_type":"code","source":["import math\n","\n","def get_chi_square_critical_values():\n","    return {\n","        # Degrees of Freedom: {Significance Levels}\n","        1: {0.05: 3.841, 0.20:1.642, 0.50:0.455},\n","        2: {0.05: 5.991, 0.20:3.219, 0.50:1.386},\n","        3: {0.05: 7.815, 0.20:4.642, 0.50:2.366},\n","        4: {0.05: 9.488, 0.20:5.989, 0.50:3.357},\n","        5: {0.05: 11.070, 0.20:7.289, 0.50:4.351},\n","        6: {0.05: 12.592, 0.20:8.558, 0.50:5.348},\n","        7: {0.05: 14.067, 0.20:9.803, 0.50:6.346},\n","        8: {0.05: 15.507, 0.20:11.030, 0.50:7.344},\n","        9: {0.05: 16.919, 0.20:12.242, 0.50:8.343},\n","        10: {0.05: 18.307, 0.20:13.442, 0.50:9.342}\n","    }\n","\n","def chi_square_test():\n","    file_path = input(\"Enter the file path for the dataset (CSV): \")\n","\n","    # Read data from CSV\n","    observed_frequencies = []\n","    with open(file_path, 'r') as file:\n","        reader = csv.reader(file)\n","        next(reader)  # Skip header if present\n","        for row in reader:\n","            try:\n","                observed_frequencies.append([int(x) for x in row])\n","            except ValueError:\n","                print(f\"Skipping invalid row: {row}\")\n","\n","    # Get total observations\n","    total_observations = sum(sum(row) for row in observed_frequencies)\n","\n","    # Calculate expected frequencies (assuming independence)\n","    num_rows = len(observed_frequencies)\n","    num_cols = len(observed_frequencies[0])\n","    expected_frequencies = [[0] * num_cols for _ in range(num_rows)]\n","\n","    for i in range(num_rows):\n","        for j in range(num_cols):\n","            row_sum = sum(observed_frequencies[i])\n","            col_sum = sum(observed_frequencies[k][j] for k in range(num_rows))\n","            expected_frequencies[i][j] = (row_sum * col_sum) / total_observations\n","\n","    # Calculate Chi-square statistic\n","    chi_square_statistic = 0\n","    for i in range(num_rows):\n","        for j in range(num_cols):\n","            chi_square_statistic += ((observed_frequencies[i][j] - expected_frequencies[i][j])**2) / expected_frequencies[i][j]\n","\n","    # Get degrees of freedom\n","    degrees_of_freedom = (num_rows - 1) * (num_cols - 1)\n","\n","    alpha = float(input(\"Enter the significance level (e.g., 0.05, 0.20, 0.50): \"))\n","    chi_square_distribution = get_chi_square_critical_values()\n","\n","    if degrees_of_freedom in chi_square_distribution and alpha in chi_square_distribution[degrees_of_freedom]:\n","        critical_value = chi_square_distribution[degrees_of_freedom][alpha]\n","        print(f\"Calculated Chi-square value: {chi_square_statistic:.3f}\")\n","        print(f\"Critical Chi-square value: {critical_value:.3f}\")\n","        if chi_square_statistic > critical_value:\n","            print(\"Result: Reject the null hypothesis.\")\n","        else:\n","            print(\"Result: Fail to reject the null hypothesis.\")\n","    else:\n","        print(\"Critical Chi-square value not available for the given degrees of freedom and alpha.\")\n","\n","chi_square_test()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"brBdj_entZ2u","executionInfo":{"status":"ok","timestamp":1737192806596,"user_tz":-330,"elapsed":37529,"user":{"displayName":"Roshini Rajan","userId":"05105296642670067175"}},"outputId":"a7b612f7-24c2-4f48-80a1-abf6177499d9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Enter the file path for the dataset (CSV): /content/drive/MyDrive/DA/k1 - xy.csv\n","Enter the significance level (e.g., 0.05, 0.20, 0.50): 0.05\n","Calculated Chi-square value: 18.177\n","Critical Chi-square value: 7.815\n","Result: Reject the null hypothesis.\n"]}]},{"cell_type":"markdown","source":["**T-TEST (ONE SAMPLE,PAIRED,UNPAIRED)**"],"metadata":{"id":"0V6DZ6AZ81zL"}},{"cell_type":"code","source":["import math\n","import csv\n","\n","def get_t_distribution():\n","    return {\n","        1: {0.05: 12.71, 0.20: 3.078, 0.50: 1.000},\n","        2: {0.05: 4.303, 0.20: 1.886, 0.50: 0.816},\n","        3: {0.05: 3.182, 0.20: 1.638, 0.50: 0.765},\n","        4: {0.05: 2.776, 0.20: 1.533, 0.50: 0.741},\n","        5: {0.05: 2.571, 0.20: 1.476, 0.50: 0.727},\n","        6: {0.05: 2.447, 0.20: 1.440, 0.50: 0.718},\n","        7: {0.05: 2.365, 0.20: 1.415, 0.50: 0.711},\n","        8: {0.05: 2.306, 0.20: 1.397, 0.50: 0.706},\n","        9: {0.05: 2.262, 0.20: 1.383, 0.50: 0.703},\n","        10: {0.05: 2.228, 0.20: 1.372, 0.50: 0.700},\n","        11: {0.05: 2.201, 0.20: 1.363, 0.50: 0.697},\n","        12: {0.05: 2.179, 0.20: 1.356, 0.50: 0.695},\n","        13: {0.05: 2.160, 0.20: 1.350, 0.50: 0.694},\n","        14: {0.05: 2.145, 0.20: 1.345, 0.50: 0.692},\n","        15: {0.05: 2.131, 0.20: 1.341, 0.50: 0.691},\n","    }\n","\n","def one_sample_test():\n","    population_mean = float(input(\"Enter the population mean: \"))\n","    sample_mean = float(input(\"Enter the sample mean: \"))\n","    std_dev = float(input(\"Enter the standard deviation: \"))\n","    sample_size = int(input(\"Enter the sample size: \"))\n","    alpha = float(input(\"Enter the significance level (e.g., 0.05, 0.20, 0.50): \"))\n","\n","    t_calculated = abs((sample_mean - population_mean) / (std_dev / math.sqrt(sample_size)))\n","    degrees_of_freedom = sample_size - 1\n","\n","    t_distribution = get_t_distribution()\n","\n","    if degrees_of_freedom in t_distribution and alpha in t_distribution[degrees_of_freedom]:\n","        t_critical = t_distribution[degrees_of_freedom][alpha]\n","        print(f\"Calculated t-value: {t_calculated:.3f}\")\n","        print(f\"Critical t-value: {t_critical}\")\n","        if t_calculated > t_critical:\n","            print(\"Result: Reject the null hypothesis.\")\n","        else:\n","            print(\"Result: Accept the null hypothesis.\")\n","    else:\n","        print(\"Critical t-value not available for the given degrees of freedom and alpha.\")\n","\n","def unpaired_test():\n","    file_path1 = input(\"Enter the file path for dataset 1 (CSV): \")\n","    with open(file_path1, 'r') as file1:\n","        reader1 = csv.reader(file1)\n","        data1 = [float(row[0]) for row in reader1]\n","    mean1 = sum(data1) / len(data1)\n","    variance1 = sum([(x - mean1)**2 for x in data1]) / (len(data1) - 1)\n","\n","    file_path2 = input(\"Enter the file path for dataset 2 (CSV): \")\n","    with open(file_path2, 'r') as file2:\n","        reader2 = csv.reader(file2)\n","        data2 = [float(row[0]) for row in reader2]\n","    mean2 = sum(data2) / len(data2)\n","    variance2 = sum([(x - mean2)**2 for x in data2]) / (len(data2) - 1)\n","\n","    alpha = float(input(\"Enter the significance level (e.g., 0.05, 0.20, 0.50): \"))\n","    n1, n2 = len(data1), len(data2)\n","    t_statistic = (mean1 - mean2) / math.sqrt((variance1 / n1) + (variance2 / n2))\n","    t_distribution = get_t_distribution()\n","    degrees_of_freedom = n1 + n2 - 2\n","\n","    if degrees_of_freedom in t_distribution and alpha in t_distribution[degrees_of_freedom]:\n","        t_critical = t_distribution[degrees_of_freedom][alpha]\n","        print(f\"Calculated t-value: {t_statistic:.3f}\")\n","        print(f\"Critical t-value: {t_critical}\")\n","        if t_statistic > t_critical:\n","            print(\"Result: Reject the null hypothesis.\")\n","        else:\n","            print(\"Result: Accept the null hypothesis.\")\n","    else:\n","        print(\"Critical t-value not available for the given degrees of freedom and alpha.\")\n","\n","def paired_test():\n","    file_path = input(\"Enter the file path for the dataset (CSV): \")\n","    with open(file_path, 'r') as file:\n","        reader = csv.reader(file)\n","        next(reader)  # Skip the header row if present\n","        data = []\n","        for row in reader:\n","            try:\n","                x1 = float(row[0])\n","                x2 = float(row[1])\n","                data.append((x1, x2))  # Store as tuples (x1, x2)\n","            except (IndexError, ValueError):\n","                print(f\"Skipping invalid row: {row}\")\n","\n","    alpha = float(input(\"Enter the significance level (e.g., 0.05, 0.20, 0.50): \"))\n","\n","    # Calculate differences\n","    differences = [x1 - x2 for x1, x2 in data]\n","    # Calculate mean and variance of differences\n","    mean_diff = sum(differences) / len(differences)\n","    variance_diff = sum([(x - mean_diff)**2 for x in differences]) / (len(differences) - 1)\n","\n","    # Calculate t-statistic\n","    t_statistic = mean_diff / (math.sqrt(variance_diff / len(differences)))\n","\n","    # Degrees of freedom\n","    degrees_of_freedom = len(differences) - 1\n","\n","    t_distribution = get_t_distribution()\n","\n","    # Check if degrees of freedom and alpha are in the t_distribution dictionary\n","    if degrees_of_freedom in t_distribution and alpha in t_distribution[degrees_of_freedom]:\n","        t_critical = t_distribution[degrees_of_freedom][alpha]\n","        print(f\"Calculated t-value: {t_statistic:.3f}\")\n","        print(f\"Critical t-value: {t_critical:.3f}\")\n","\n","        # Check if calculated t-statistic exceeds the critical value\n","        if abs(t_statistic) > t_critical:  # Use abs() for two-tailed test\n","            print(\"Result: Reject the null hypothesis.\")\n","        else:\n","            print(\"Result: Fail to reject the null hypothesis.\")\n","    else:\n","        print(\"Critical t-value not available for the given degrees of freedom and alpha.\")\n","\n","def main():\n","    print(\"Choose the type of t-test you would like to perform:\")\n","    print(\"1. One-Sample t-test\")\n","    print(\"2. Unpaired t-test\")\n","    print(\"3. Paired t-test\")\n","\n","    choice = int(input(\"Enter the number corresponding to your choice: \"))\n","\n","    if choice == 1:\n","        one_sample_test()\n","    elif choice == 2:\n","        unpaired_test()\n","    elif choice == 3:\n","        paired_test()\n","    else:\n","        print(\"Invalid choice. Please select 1, 2, or 3.\")\n","\n","# Run the main function to let the user choose the test\n","main()\n"],"metadata":{"id":"GcTJJhQsI9-W"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**ANOVA TEST**"],"metadata":{"id":"cLMw0ZsKRwdQ"}},{"cell_type":"code","source":["import pandas as pd\n","def get_f_distribution():\n","    return {\n","       0.05: {\n","        1: {\n","            1: 161.4, 2: 18.51, 3: 10.13, 4: 7.71, 5: 6.61, 6: 5.99,\n","            7: 5.59, 8: 5.32, 9: 5.12, 10: 4.96, 11: 4.84, 12: 4.75,\n","            13: 4.67, 14: 4.60, 15: 4.54, 16: 4.49, 17: 4.45, 18: 4.41,\n","            19: 4.3807, 20: 4.3512\n","        },\n","        2: {\n","            1: 199.5, 2: 19.0, 3: 9.5521, 4: 6.9443, 5: 5.7861, 6: 5.1433,\n","            7: 4.7374, 8: 4.459, 9: 4.2565, 10: 4.1028, 11: 3.9823, 12: 3.8853,\n","            13: 3.8056, 14: 3.7389, 15: 3.6823, 16: 3.6337, 17: 3.5915, 18: 3.5546,\n","            19: 3.5219, 20: 3.4928\n","        },\n","        3: {\n","            1: 215.7073, 2: 19.1643, 3: 9.2766, 4: 6.5914, 5: 5.4095, 6: 4.7571,\n","            7: 4.3468, 8: 4.0662, 9: 3.8625, 10: 3.7083, 11: 3.5874, 12: 3.4903,\n","            13: 3.4105, 14: 3.3439, 15: 3.2874, 16: 3.2389, 17: 3.1968, 18: 3.1599,\n","            19: 3.1274, 20: 3.0984\n","        }\n","     },\n","     0.005 : {\n","          1: {\n","        1: 16211, 2: 20000, 3: 21615, 4: 31.33, 5: 22.78, 6: 18.63,\n","        7: 16.24, 8: 14.69, 9: 13.61, 10: 12.83, 11: 12.21, 12: 11.75,\n","        13: 11.36, 14: 11.06, 15: 10.80, 16: 10.58, 17: 10.40, 18: 10.22,\n","        19: 10.07, 20: 9.94\n","    },\n","    2: {\n","        1: 198.5, 2: 199.0, 3: 199.2, 4: 26.28, 5: 18.31, 6: 14.54,\n","        7: 12.40, 8: 11.04, 9: 10.11, 10: 9.43, 11: 8.91, 12: 8.51,\n","        13: 8.14, 14: 7.92, 15: 7.70, 16: 7.51, 17: 7.35, 18: 7.21,\n","        19: 7.09, 20: 6.99\n","    },\n","    3: {\n","        1: 55.55, 2: 49.80, 3: 47.47, 4: 24.26, 5: 16.53, 6: 12.92,\n","        7: 10.80, 8: 9.60, 9: 8.72, 10: 8.08, 11: 7.53, 12: 7.13,\n","        13: 6.82, 14: 6.58, 15: 6.36, 16: 6.16, 17: 6.03, 18: 5.92,\n","        19: 5.82, 20: 5.74\n","    }\n","\n","\n","       },\n","     0.01 :\n","       {\n","           1: {\n","        1: 4052, 2: 4999.5, 3: 5403, 4: 21.2, 5: 16.26, 6: 13.75,\n","        7: 12.25, 8: 11.26, 9: 10.56, 10: 10.04, 11: 9.65, 12: 9.33,\n","        13: 9.07, 14: 8.86, 15: 8.68, 16: 8.53, 17: 8.4, 18: 8.29,\n","        19: 8.18, 20: 8.10\n","    },\n","    2: {\n","        1: 98.5, 2: 99.0, 3: 99.17, 4: 30.82, 5: 18.0, 6: 13.27,\n","        7: 10.92, 8: 8.65, 9: 8.02, 10: 7.56, 11: 7.21, 12: 6.93,\n","        13: 6.71, 14: 6.51, 15: 6.33, 16: 6.23, 17: 6.11, 18: 6.01,\n","        19: 5.93, 20: 5.85\n","    },\n","    3: {\n","        1: 34.12, 2: 29.46, 3: 18.0, 4: 12.06, 5: 9.78, 6: 8.59,\n","        7: 7.74, 8: 7.15, 9: 6.55, 10: 6.22, 11: 5.95, 12: 5.75,\n","        13: 5.56, 14: 5.4, 15: 5.29, 16: 5.18, 17: 5.09, 18: 5.01,\n","        19: 4.94, 20: 4.88\n","    }\n","       } ,\n","    0.025 :\n","       {\n","            1: {\n","        1: 647.8, 2: 799.5, 3: 864.2, 4: 12.22, 5: 10.01, 6: 8.81,\n","        7: 8.07, 8: 7.57, 9: 7.21, 10: 6.94, 11: 6.72, 12: 6.55,\n","        13: 6.40, 14: 6.30, 15: 6.20, 16: 6.12, 17: 6.04, 18: 5.98,\n","        19: 5.92, 20: 5.87\n","    },\n","    2: {\n","        1: 38.51, 2: 39.00, 3: 39.17, 4: 10.65, 5: 8.63, 6: 7.26,\n","        7: 6.54, 8: 6.06, 9: 5.71, 10: 5.46, 11: 5.26, 12: 5.10,\n","        13: 4.97, 14: 4.86, 15: 4.77, 16: 4.69, 17: 4.62, 18: 4.56,\n","        19: 4.51, 20: 4.46\n","    },\n","    3: {\n","        1: 17.44, 2: 16.04, 3: 15.44, 4: 9.98, 5: 7.76, 6: 6.60,\n","        7: 5.89, 8: 5.42, 9: 5.08, 10: 4.83, 11: 4.63, 12: 4.47,\n","        13: 4.34, 14: 4.24, 15: 4.14, 16: 4.08, 17: 4.02, 18: 3.95,\n","        19: 3.90, 20: 3.86\n","    }\n","       } ,\n","      0.10 :\n","       {\n","        1: {\n","        1: 39.86, 2: 8.53, 3: 5.54, 4: 4.54, 5: 4.06, 6: 3.78, 7: 3.59, 8: 3.46, 9: 3.36,\n","        10: 3.29, 11: 3.23, 12: 3.18, 13: 3.14, 14: 3.10, 15: 3.07, 16: 3.05, 17: 3.03,\n","        18: 3.01, 19: 2.99, 20: 2.97\n","    },\n","    2: {\n","        1: 49.50, 2: 9.00, 3: 5.46, 4: 4.32, 5: 3.78, 6: 3.46, 7: 3.29, 8: 3.11, 9: 3.01,\n","        10: 2.92, 11: 2.86, 12: 2.81, 13: 2.76, 14: 2.73, 15: 2.70, 16: 2.67, 17: 2.64,\n","        18: 2.62, 19: 2.61, 20: 2.59\n","    },\n","    3: {\n","        1: 53.59, 2: 9.16, 3: 5.39, 4: 4.19, 5: 3.62, 6: 3.29, 7: 3.07, 8: 2.92, 9: 2.81,\n","        10: 2.73, 11: 2.66, 12: 2.61, 13: 2.57, 14: 2.52, 15: 2.49, 16: 2.46, 17: 2.44,\n","        18: 2.42, 19: 2.40, 20: 2.38\n","    }\n","       }\n","    }\n","\n","file_path = \"/content/plant - Sheet1.csv\"\n","data = pd.read_csv(file_path, header=None, names=[\"Group\", \"Value\"])\n","\n","\n","group_means = data.groupby(\"Group\")[\"Value\"].mean().round(2)\n","\n","overall_mean = data[\"Value\"].mean().round(2)\n","\n","SSB = sum(data.groupby(\"Group\").size() * (group_means - overall_mean) ** 2)\n","SSW = sum((data[\"Value\"] - data.groupby(\"Group\")[\"Value\"].transform(\"mean\")) ** 2)\n","\n","df_between = len(group_means) - 1\n","df_within = len(data) - len(group_means)\n","\n","MSB = SSB / df_between\n","MSW = SSW / df_within\n","\n","F_calculated = MSB / MSW\n","alpha = float(input(\"Enter the significance level (e.g., 0.005, 0.01, 0.025, 0.05, 0.10): \"))\n","f_distribution = get_f_distribution()\n","critical_value = f_distribution[alpha][df_between][df_within]\n","\n","# Print results\n","print(\"ANOVA Results:\")\n","print(f\"SSB (Sum of Squares Between): {SSB:.2f}\")\n","print(f\"SSW (Sum of Squares Within): {SSW:.2f}\")\n","print(f\"F-calculated: {F_calculated:.2f}\")\n","print(f\"Degrees of Freedom Between: {df_between}\")\n","print(f\"Degrees of Freedom Within: {df_within}\")\n","print(f\"Critical Value (F-table): {critical_value}\")\n","\n","# Hypothesis testing\n","if F_calculated > critical_value:\n","    print(\" Reject the null hypothesis. There is a significant difference between the group means.\")\n","else:\n","    print(\"Accept the null hypothesis. There is no significant difference between the group means.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":373},"id":"7ymkK9i3HxqO","executionInfo":{"status":"error","timestamp":1738142596967,"user_tz":-330,"elapsed":395,"user":{"displayName":"Roshini Rajan","userId":"05105296642670067175"}},"outputId":"1007fcf1-490e-4dbc-8d75-37206a30a466"},"execution_count":3,"outputs":[{"output_type":"error","ename":"FileNotFoundError","evalue":"[Errno 2] No such file or directory: '/content/plant - Sheet1.csv'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-3-7e63ef246d82>\u001b[0m in \u001b[0;36m<cell line: 109>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0mfile_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"/content/plant - Sheet1.csv\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Group\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Value\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/plant - Sheet1.csv'"]}]},{"cell_type":"code","source":["def get_f_distribution():\n","    return {\n","       0.05: {\n","        1: {\n","            1: 161.4, 2: 18.51, 3: 10.13, 4: 7.71, 5: 6.61, 6: 5.99,\n","            7: 5.59, 8: 5.32, 9: 5.12, 10: 4.96, 11: 4.84, 12: 4.75,\n","            13: 4.67, 14: 4.60, 15: 4.54, 16: 4.49, 17: 4.45, 18: 4.41,\n","            19: 4.3807, 20: 4.3512\n","        },\n","        2: {\n","            1: 199.5, 2: 19.0, 3: 9.5521, 4: 6.9443, 5: 5.7861, 6: 5.1433,\n","            7: 4.7374, 8: 4.459, 9: 4.2565, 10: 4.1028, 11: 3.9823, 12: 3.8853,\n","            13: 3.8056, 14: 3.7389, 15: 3.6823, 16: 3.6337, 17: 3.5915, 18: 3.5546,\n","            19: 3.5219, 20: 3.4928\n","        },\n","        3: {\n","            1: 215.7073, 2: 19.1643, 3: 9.2766, 4: 6.5914, 5: 5.4095, 6: 4.7571,\n","            7: 4.3468, 8: 4.0662, 9: 3.8625, 10: 3.7083, 11: 3.5874, 12: 3.4903,\n","            13: 3.4105, 14: 3.3439, 15: 3.2874, 16: 3.2389, 17: 3.1968, 18: 3.1599,\n","            19: 3.1274, 20: 3.0984\n","        }\n","     },\n","     0.005 : {\n","          1: {\n","        1: 16211, 2: 20000, 3: 21615, 4: 31.33, 5: 22.78, 6: 18.63,\n","        7: 16.24, 8: 14.69, 9: 13.61, 10: 12.83, 11: 12.21, 12: 11.75,\n","        13: 11.36, 14: 11.06, 15: 10.80, 16: 10.58, 17: 10.40, 18: 10.22,\n","        19: 10.07, 20: 9.94\n","    },\n","    2: {\n","        1: 198.5, 2: 199.0, 3: 199.2, 4: 26.28, 5: 18.31, 6: 14.54,\n","        7: 12.40, 8: 11.04, 9: 10.11, 10: 9.43, 11: 8.91, 12: 8.51,\n","        13: 8.14, 14: 7.92, 15: 7.70, 16: 7.51, 17: 7.35, 18: 7.21,\n","        19: 7.09, 20: 6.99\n","    },\n","    3: {\n","        1: 55.55, 2: 49.80, 3: 47.47, 4: 24.26, 5: 16.53, 6: 12.92,\n","        7: 10.80, 8: 9.60, 9: 8.72, 10: 8.08, 11: 7.53, 12: 7.13,\n","        13: 6.82, 14: 6.58, 15: 6.36, 16: 6.16, 17: 6.03, 18: 5.92,\n","        19: 5.82, 20: 5.74\n","    }\n","\n","\n","       },\n","     0.01 :\n","       {\n","           1: {\n","        1: 4052, 2: 4999.5, 3: 5403, 4: 21.2, 5: 16.26, 6: 13.75,\n","        7: 12.25, 8: 11.26, 9: 10.56, 10: 10.04, 11: 9.65, 12: 9.33,\n","        13: 9.07, 14: 8.86, 15: 8.68, 16: 8.53, 17: 8.4, 18: 8.29,\n","        19: 8.18, 20: 8.10\n","    },\n","    2: {\n","        1: 98.5, 2: 99.0, 3: 99.17, 4: 30.82, 5: 18.0, 6: 13.27,\n","        7: 10.92, 8: 8.65, 9: 8.02, 10: 7.56, 11: 7.21, 12: 6.93,\n","        13: 6.71, 14: 6.51, 15: 6.33, 16: 6.23, 17: 6.11, 18: 6.01,\n","        19: 5.93, 20: 5.85\n","    },\n","    3: {\n","        1: 34.12, 2: 29.46, 3: 18.0, 4: 12.06, 5: 9.78, 6: 8.59,\n","        7: 7.74, 8: 7.15, 9: 6.55, 10: 6.22, 11: 5.95, 12: 5.75,\n","        13: 5.56, 14: 5.4, 15: 5.29, 16: 5.18, 17: 5.09, 18: 5.01,\n","        19: 4.94, 20: 4.88\n","    }\n","       } ,\n","    0.025 :\n","       {\n","            1: {\n","        1: 647.8, 2: 799.5, 3: 864.2, 4: 12.22, 5: 10.01, 6: 8.81,\n","        7: 8.07, 8: 7.57, 9: 7.21, 10: 6.94, 11: 6.72, 12: 6.55,\n","        13: 6.40, 14: 6.30, 15: 6.20, 16: 6.12, 17: 6.04, 18: 5.98,\n","        19: 5.92, 20: 5.87\n","    },\n","    2: {\n","        1: 38.51, 2: 39.00, 3: 39.17, 4: 10.65, 5: 8.63, 6: 7.26,\n","        7: 6.54, 8: 6.06, 9: 5.71, 10: 5.46, 11: 5.26, 12: 5.10,\n","        13: 4.97, 14: 4.86, 15: 4.77, 16: 4.69, 17: 4.62, 18: 4.56,\n","        19: 4.51, 20: 4.46\n","    },\n","    3: {\n","        1: 17.44, 2: 16.04, 3: 15.44, 4: 9.98, 5: 7.76, 6: 6.60,\n","        7: 5.89, 8: 5.42, 9: 5.08, 10: 4.83, 11: 4.63, 12: 4.47,\n","        13: 4.34, 14: 4.24, 15: 4.14, 16: 4.08, 17: 4.02, 18: 3.95,\n","        19: 3.90, 20: 3.86\n","    }\n","       } ,\n","      0.10 :\n","       {\n","        1: {\n","        1: 39.86, 2: 8.53, 3: 5.54, 4: 4.54, 5: 4.06, 6: 3.78, 7: 3.59, 8: 3.46, 9: 3.36,\n","        10: 3.29, 11: 3.23, 12: 3.18, 13: 3.14, 14: 3.10, 15: 3.07, 16: 3.05, 17: 3.03,\n","        18: 3.01, 19: 2.99, 20: 2.97\n","    },\n","    2: {\n","        1: 49.50, 2: 9.00, 3: 5.46, 4: 4.32, 5: 3.78, 6: 3.46, 7: 3.29, 8: 3.11, 9: 3.01,\n","        10: 2.92, 11: 2.86, 12: 2.81, 13: 2.76, 14: 2.73, 15: 2.70, 16: 2.67, 17: 2.64,\n","        18: 2.62, 19: 2.61, 20: 2.59\n","    },\n","    3: {\n","        1: 53.59, 2: 9.16, 3: 5.39, 4: 4.19, 5: 3.62, 6: 3.29, 7: 3.07, 8: 2.92, 9: 2.81,\n","        10: 2.73, 11: 2.66, 12: 2.61, 13: 2.57, 14: 2.52, 15: 2.49, 16: 2.46, 17: 2.44,\n","        18: 2.42, 19: 2.40, 20: 2.38\n","    }\n","       }\n","    }"],"metadata":{"id":"VTE08GYcX5Q9","executionInfo":{"status":"ok","timestamp":1738144401389,"user_tz":-330,"elapsed":364,"user":{"displayName":"Roshini Rajan","userId":"05105296642670067175"}}},"execution_count":18,"outputs":[]},{"cell_type":"code","source":["import pandas as pd\n","\n","file_path = \"/content/drive/MyDrive/DA/anova_2_way - Sheet1.csv\"\n","data = pd.read_csv(file_path, header=None, names=[\"Group\", \"Level\", \"Value\"])\n","\n","\n","overall_mean = data[\"Value\"].mean()\n","\n","mean_group = data.groupby(\"Group\")[\"Value\"].mean()\n","mean_level = data.groupby(\"Level\")[\"Value\"].mean()\n","\n","mean_group_level = data.groupby([\"Group\", \"Level\"])[\"Value\"].mean()\n","\n","SST =sum((data[\"Value\"] - overall_mean) ** 2)\n","\n","SSA = sum([len(data[data[\"Group\"] == group]) * (mean_group[group] - overall_mean) ** 2 for group in mean_group.index])\n","\n","SSB = sum([len(data[data[\"Level\"] == level]) * (mean_level[level] - overall_mean) ** 2 for level in mean_level.index])\n","\n","SSAB = sum([len(data[(data[\"Group\"] == group) & (data[\"Level\"] == level)]) *\n","            (mean_group_level[(group, level)] - mean_group[group] - mean_level[level] + overall_mean) ** 2\n","            for group in mean_group.index for level in mean_level.index])\n","\n","SSE = SST - SSA - SSB - SSAB\n","\n","\n","df_group = len(mean_group) - 1\n","df_level = len(mean_level) - 1\n","df_interaction = df_group * df_level\n","df_error = len(data) - (len(mean_group) * len(mean_level))\n","\n","# Mean Squares\n","MS_group = SSA / df_group\n","MS_level = SSB / df_level\n","MS_interaction = SSAB / df_interaction\n","MS_error = SSE / df_error\n","\n","# F-statistics\n","F_group = MS_group / MS_error\n","F_level = MS_level / MS_error\n","F_interaction = MS_interaction / MS_error\n","\n","alpha = float(input(\"Enter the significance level (e.g., 0.005, 0.01, 0.025, 0.05, 0.10): \"))\n","f_distribution = get_f_distribution()\n","\n","critical_value_group = f_distribution[alpha][df_group][df_error]\n","critical_value_level = f_distribution[alpha][df_level][df_error]\n","critical_value_interaction = f_distribution[alpha][df_interaction][df_error]\n","\n","# Print results\n","print(\"Two-Way ANOVA Results:\")\n","print(f\"SST (Sum of Squares Total): {SST:.2f}\")\n","print(f\"SSA (Sum of Squares Group): {SSA:.2f}\")\n","print(f\"SSB (Sum of Squares Level): {SSB:.2f}\")\n","print(f\"SSAB (Sum of Squares Interaction): {SSAB:.2f}\")\n","print(f\"SSE (Sum of Squares Error): {SSE:.2f}\")\n","print(f\"F-statistic Group: {F_group:.2f}\")\n","print(f\"F-statistic Level: {F_level:.2f}\")\n","print(f\"F-statistic Interaction: {F_interaction:.2f}\")\n","print(f\"Critical Value Group: {critical_value_group}\")\n","print(f\"Critical Value Level: {critical_value_level}\")\n","print(f\"Critical Value Interaction: {critical_value_interaction}\")\n","\n","#Group\n","if F_group > critical_value_group:\n","    print(\"Reject the null hypothesis for Group.\")\n","else:\n","    print(\"Accept the null hypothesis for Group.\")\n","\n","#Level\n","if F_level > critical_value_level:\n","    print(\"Reject the null hypothesis for Level.\")\n","else:\n","    print(\"Accept the null hypothesis for Level.\")\n","\n","#Interaction\n","if F_interaction > critical_value_interaction:\n","    print(\"Reject the null hypothesis for Interaction.\")\n","else:\n","    print(\"Accept the null hypothesis for Interaction.\")"],"metadata":{"id":"-U_Br4RAQX0d","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1738143257239,"user_tz":-330,"elapsed":5198,"user":{"displayName":"Roshini Rajan","userId":"05105296642670067175"}},"outputId":"a951fdbf-2f5a-4c9c-8339-5ff570518d69"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["Enter the significance level (e.g., 0.005, 0.01, 0.025, 0.05, 0.10): 0.05\n","Two-Way ANOVA Results:\n","SST (Sum of Squares Total): 1415.67\n","SSA (Sum of Squares Group): 85.33\n","SSB (Sum of Squares Level): 1287.17\n","SSAB (Sum of Squares Interaction): 5.17\n","SSE (Sum of Squares Error): 38.00\n","F-statistic Group: 13.47\n","F-statistic Level: 101.62\n","F-statistic Interaction: 0.41\n","Critical Value Group: 5.99\n","Critical Value Level: 5.1433\n","Critical Value Interaction: 5.1433\n","Reject the null hypothesis for Group.\n","Reject the null hypothesis for Level.\n","Accept the null hypothesis for Interaction.\n"]}]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-AZzqA3OXeOu","executionInfo":{"status":"ok","timestamp":1738142537695,"user_tz":-330,"elapsed":21261,"user":{"displayName":"Roshini Rajan","userId":"05105296642670067175"}},"outputId":"f5ec51ee-c6ad-46e7-98b7-14a3797ff0a5"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","\n","# Load the dataset from the CSV file\n","file_path = \"/content/drive/MyDrive/DA/anova_2_way - Sheet1.csv\"\n","data = pd.read_csv(file_path, header=None, names=[\"Group\", \"Level\", \"Value\"])\n","\n","# Calculate overall mean\n","#overall_mean = round(data[\"Value\"].mean(), 2)\n","\n","# Calculate means for each factor level\n","mean_group = data.groupby(\"Group\")[\"Value\"].mean().round(2)\n","mean_level = data.groupby(\"Level\")[\"Value\"].mean().round(2)\n","overall_mean = round(mean_group.mean(), 2)\n","\n","# Calculate means for each combination of Group and Level\n","mean_group_level = data.groupby([\"Group\", \"Level\"])[\"Value\"].mean().round(2)\n","\n","# Calculate Sum of Squares Total (SST)\n","SST = round(sum((data[\"Value\"] - overall_mean) ** 2), 2)\n","\n","# Calculate Sum of Squares for Group (SSA)\n","SSA = round(sum([len(data[data[\"Group\"] == group]) * (mean_group[group] - overall_mean) ** 2 for group in mean_group.index]), 2)\n","\n","# Calculate Sum of Squares for Level (SSB)\n","SSB = round(sum([len(data[data[\"Level\"] == level]) * (mean_level[level] - overall_mean) ** 2 for level in mean_level.index]), 2)\n","\n","# Calculate Sum of Squares for Interaction (SSAB)\n","SSAB = round(sum([len(data[(data[\"Group\"] == group) & (data[\"Level\"] == level)]) *\n","            (mean_group_level[(group, level)] - mean_group[group] - mean_level[level] + overall_mean) ** 2\n","            for group in mean_group.index for level in mean_level.index]), 2)\n","\n","# Calculate Sum of Squares Error (SSE)\n","SSE = round(SST - SSA - SSB - SSAB, 2)\n","\n","# Degrees of Freedom\n","df_group = len(mean_group) - 1  # Degrees of freedom for Group\n","df_level = len(mean_level) - 1  # Degrees of freedom for Level\n","df_interaction = df_group * df_level  # Degrees of freedom for Interaction\n","df_error = len(data) - (len(mean_group) * len(mean_level))  # Degrees of freedom for Error\n","\n","# Mean Squares\n","MS_group = round(SSA / df_group, 2)  # Mean square for Group\n","MS_level = round(SSB / df_level, 2)  # Mean square for Level\n","MS_interaction = round(SSAB / df_interaction, 2)  # Mean square for Interaction\n","MS_error = round(SSE / df_error, 2)  # Mean square for Error\n","\n","# F-statistics\n","F_group = round(MS_group / MS_error, 2)  # F-statistic for Group\n","F_level = round(MS_level / MS_error, 2)  # F-statistic for Level\n","F_interaction = round(MS_interaction / MS_error, 2)  # F-statistic for Interaction\n","\n","# Critical F-values (from F-distribution table or function)\n","alpha = float(input(\"Enter the significance level (e.g., 0.005, 0.01, 0.025, 0.05, 0.10): \"))\n","f_distribution = get_f_distribution()\n","\n","critical_value_group = round(f_distribution[alpha][df_group][df_error], 2)\n","critical_value_level = round(f_distribution[alpha][df_level][df_error], 2)\n","critical_value_interaction = round(f_distribution[alpha][df_interaction][df_error], 2)\n","\n","# Print results\n","print(\"Two-Way ANOVA Results:\")\n","print(f\"SST (Sum of Squares Total): {SST}\")\n","print(f\"SSA (Sum of Squares Group): {SSA}\")\n","print(f\"SSB (Sum of Squares Level): {SSB}\")\n","print(f\"SSAB (Sum of Squares Interaction): {SSAB}\")\n","print(f\"SSE (Sum of Squares Error): {SSE}\")\n","print(f\"F-statistic Group: {F_group}\")\n","print(f\"F-statistic Level: {F_level}\")\n","print(f\"F-statistic Interaction: {F_interaction}\")\n","print(f\"Critical Value Group: {critical_value_group}\")\n","print(f\"Critical Value Level: {critical_value_level}\")\n","print(f\"Critical Value Interaction: {critical_value_interaction}\")\n","\n","# Hypothesis testing for Group\n","if F_group > critical_value_group:\n","    print(\"Reject the null hypothesis for Group. There is a significant effect.\")\n","else:\n","    print(\"Accept the null hypothesis for Group. There is no significant effect.\")\n","\n","# Hypothesis testing for Level\n","if F_level > critical_value_level:\n","    print(\"Reject the null hypothesis for Level. There is a significant effect.\")\n","else:\n","    print(\"Accept the null hypothesis for Level. There is no significant effect.\")\n","\n","# Hypothesis testing for Interaction\n","if F_interaction > critical_value_interaction:\n","    print(\"Reject the null hypothesis for Interaction. There is a significant interaction effect.\")\n","else:\n","    print(\"Accept the null hypothesis for Interaction. There is no significant interaction effect.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oxy6WEJPYZwt","executionInfo":{"status":"ok","timestamp":1738144639113,"user_tz":-330,"elapsed":4099,"user":{"displayName":"Roshini Rajan","userId":"05105296642670067175"}},"outputId":"49437d72-3949-487a-a8fa-b6806d308702"},"execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":["Enter the significance level (e.g., 0.005, 0.01, 0.025, 0.05, 0.10): 0.05\n","Two-Way ANOVA Results:\n","SST (Sum of Squares Total): 1415.67\n","SSA (Sum of Squares Group): 85.23\n","SSB (Sum of Squares Level): 1287.17\n","SSAB (Sum of Squares Interaction): 5.17\n","SSE (Sum of Squares Error): 38.1\n","F-statistic Group: 13.42\n","F-statistic Level: 101.35\n","F-statistic Interaction: 0.41\n","Critical Value Group: 5.99\n","Critical Value Level: 5.14\n","Critical Value Interaction: 5.14\n","Reject the null hypothesis for Group. There is a significant effect.\n","Reject the null hypothesis for Level. There is a significant effect.\n","Accept the null hypothesis for Interaction. There is no significant interaction effect.\n"]}]}]}