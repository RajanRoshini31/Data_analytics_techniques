{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.datasets import load_iris\n",
        "\n",
        "class SVM:\n",
        "    def __init__(self, lr=0.001, reg=0.01, epochs=1000):\n",
        "        self.lr = lr\n",
        "        self.reg = reg\n",
        "        self.epochs = epochs\n",
        "        self.w = None\n",
        "        self.b = 0\n",
        "    def fit(self, X, y):\n",
        "        self.w = np.zeros(X.shape[1])\n",
        "        self.b = 0\n",
        "\n",
        "        for epoch in range(self.epochs):\n",
        "            for i in range(len(X)):\n",
        "                condition = y[i] * (np.dot(X[i], self.w) + self.b)\n",
        "\n",
        "                if condition >= 1:\n",
        "                    dw = self.reg * self.w\n",
        "                    db = 0\n",
        "                else:\n",
        "                    dw = self.reg * self.w - np.dot(X[i], y[i])\n",
        "                    db = -y[i]\n",
        "\n",
        "                self.w -= self.lr * dw\n",
        "                self.b -= self.lr * db\n",
        "\n",
        "    def predict(self, X):\n",
        "        return np.sign(np.dot(X, self.w) + self.b)\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "y_binary = np.where(y == 0, 1, -1)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y_binary, test_size=0.2, random_state=42)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "svm = SVM(lr=0.01, reg=0.01, epochs=1000)\n",
        "svm.fit(X_train, y_train)\n",
        "\n",
        "predictions = svm.predict(X_test)\n",
        "\n",
        "class_names = iris.target_names\n",
        "predicted_class_names = [class_names[0] if p == 1 else class_names[1] if p == 0 else class_names[2] for p in predictions]\n",
        "\n",
        "distinct_classes = np.unique(predicted_class_names)\n",
        "print(\"\\nDistinct Predicted Classes:\")\n",
        "print(distinct_classes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wt_4vQTQlP78",
        "outputId": "fd150b2a-9978-4e76-ad61-e246d3b09f67"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Distinct Predicted Classes:\n",
            "['setosa' 'virginica']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "df = pd.read_csv('/content/gnb_diabetes_dataset.csv')\n",
        "X = df.drop('class', axis=1).values\n",
        "y = df['class'].values\n",
        "print(df.head())\n",
        "classes, class_counts = np.unique(y, return_counts=True)\n",
        "prior_probabilities = class_counts / len(y)\n",
        "means = {}\n",
        "variances = {}\n",
        "for class_label in classes:\n",
        "    X_class = X[y == class_label]\n",
        "    means[class_label] = np.mean(X_class, axis=0)\n",
        "    variances[class_label] = np.var(X_class, axis=0)\n",
        "def gaussian_pdf(x, mean, var):\n",
        "    return (1 / np.sqrt(2 * np.pi * var)) * np.exp(-(x - mean) ** 2 / (2 * var))\n",
        "def gnb_predict(X):\n",
        "    predictions = []\n",
        "    for sample in X:\n",
        "        class_probabilities = []\n",
        "        for class_label in classes:\n",
        "            class_prob = np.log(prior_probabilities[class_label])\n",
        "            for i in range(len(sample)):\n",
        "                mean = means[class_label][i]\n",
        "                var = variances[class_label][i]\n",
        "                class_prob += np.log(gaussian_pdf(sample[i], mean, var))\n",
        "\n",
        "            class_probabilities.append(class_prob)\n",
        "        predicted_class = classes[np.argmax(class_probabilities)]\n",
        "        predictions.append(predicted_class)\n",
        "    return np.array(predictions)\n",
        "\n",
        "user_input = input(\"Enter the feature values separated by spaces: \")\n",
        "new_data = np.array([list(map(float, user_input.split()))])\n",
        "predictions = gnb_predict(new_data)\n",
        "print(f\"Predictions for new data {new_data}:{predictions}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rFRg2P3VffqE",
        "outputId": "4921c860-e6c3-4a1d-e4bc-8f70aa27e75f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Age  Glucose   BMI  class\n",
            "0   25       85  22.5      0\n",
            "1   35       90  24.1      0\n",
            "2   50      140  30.5      1\n",
            "3   45      130  28.2      1\n",
            "4   30      100  26.5      0\n",
            "Enter the feature values separated by spaces: 52 150 32.15 \n",
            "Predictions for new data [[ 52.   150.    32.15]]:[1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import math\n",
        "\n",
        "df = pd.read_csv('/content/MNB_dataset.csv')\n",
        "new_input = input(\"Enter the words in the new document (space-separated): \")\n",
        "new_doc = new_input.split()\n",
        "\n",
        "total_sports = df['sports'].sum()\n",
        "total_politics = df['politics'].sum()\n",
        "\n",
        "total_words = total_sports + total_politics\n",
        "\n",
        "P_sports = total_sports / total_words\n",
        "P_politics = total_politics / total_words\n",
        "\n",
        "def calculate_likelihood(word, class_name):\n",
        "    word_count = df.loc[df['word'] == word, class_name].values\n",
        "    if len(word_count) == 0:  # If the word is not in the dataset, use Laplace smoothing\n",
        "        return 1 / (total_sports + len(df)) if class_name == 'sports' else 1 / (total_politics + len(df))\n",
        "    else:\n",
        "        return (word_count[0] + 1) / (total_sports + len(df)) if class_name == 'sports' else (word_count[0] + 1) / (total_politics + len(df))\n",
        "\n",
        "# Step 6: Calculate P(new_doc | sports) and P(new_doc | politics)\n",
        "P_new_doc_given_sports = P_sports\n",
        "P_new_doc_given_politics = P_politics\n",
        "\n",
        "for word in new_doc:\n",
        "    P_new_doc_given_sports *= calculate_likelihood(word, 'sports')\n",
        "    P_new_doc_given_politics *= calculate_likelihood(word, 'politics')\n",
        "\n",
        "posterior_sports = P_new_doc_given_sports * P_sports\n",
        "posterior_politics = P_new_doc_given_politics * P_politics\n",
        "\n",
        "total_posterior = posterior_sports + posterior_politics\n",
        "posterior_sports /= total_posterior\n",
        "posterior_politics /= total_posterior\n",
        "\n",
        "print(f\"Posterior probability for sports: {posterior_sports}\")\n",
        "print(f\"Posterior probability for politics: {posterior_politics}\")\n",
        "\n",
        "if posterior_sports > posterior_politics:\n",
        "    print(\"The document is classified as: sports\")\n",
        "else:\n",
        "    print(\"The document is classified as: politics\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OKsSAn0Gl55d",
        "outputId": "36e9c235-f5d3-429b-f36c-9d112190dd88"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter the words in the new document (space-separated): election\n",
            "Posterior probability for sports: 0.2125984251968504\n",
            "Posterior probability for politics: 0.7874015748031497\n",
            "The document is classified as: politics\n"
          ]
        }
      ]
    }
  ]
}